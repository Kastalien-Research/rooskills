{
  "markdown": "Get comprehensive, actionable reviews directly in your PRs. [Try Roo's PR Reviewer](https://roocode.com/reviewer?utm_source=docs&utm_medium=banner&utm_campaign=reviewer_promo)\n\n[Skip to main content](https://docs.roocode.com/advanced-usage/local-models#__docusaurus_skipToContent_fallback)\n\n[![Roo Code Logo](https://docs.roocode.com/img/roo-code-logo-dark.png)](https://docs.roocode.com/)\n\n`ctrl`  `K`\n\n[Reddit](https://www.reddit.com/r/RooCode/ \"Reddit\")[Discord](https://discord.gg/roocode \"Discord\")\n\n[20.3k](https://github.com/RooCodeInc/Roo-Code \"GitHub Repository\") [Install ·936.4k](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline \"Install VS Code Extension\")\n\n- [Welcome](https://docs.roocode.com/)\n- [Getting Started](https://docs.roocode.com/advanced-usage/local-models#)\n\n- [Tutorial Videos](https://docs.roocode.com/advanced-usage/local-models#)\n\n- [Roo Code Cloud](https://docs.roocode.com/advanced-usage/local-models#)\n\n- Features\n\n  - [API Configuration Profiles](https://docs.roocode.com/features/api-configuration-profiles)\n  - [Auto-Approving Actions](https://docs.roocode.com/features/auto-approving-actions)\n  - [Boomerang Tasks](https://docs.roocode.com/features/boomerang-tasks)\n  - [Browser Use](https://docs.roocode.com/features/browser-use)\n  - [Checkpoints](https://docs.roocode.com/features/checkpoints)\n  - [Code Actions](https://docs.roocode.com/features/code-actions)\n  - [Codebase Indexing](https://docs.roocode.com/features/codebase-indexing)\n  - [Custom Instructions](https://docs.roocode.com/features/custom-instructions)\n  - [Diagnostics Integration](https://docs.roocode.com/features/diagnostics-integration)\n  - [Customizing Modes](https://docs.roocode.com/features/custom-modes)\n  - [Diff/Fast Edits](https://docs.roocode.com/features/fast-edits)\n  - [Enhance Prompt](https://docs.roocode.com/features/enhance-prompt)\n  - [Import/Export/Reset Settings](https://docs.roocode.com/features/settings-management)\n  - [Intelligent Context Condensing](https://docs.roocode.com/features/intelligent-context-condensing)\n  - [Keyboard Navigation](https://docs.roocode.com/features/keyboard-shortcuts)\n  - [Roo Code Marketplace](https://docs.roocode.com/features/marketplace)\n  - [Message Queueing](https://docs.roocode.com/features/message-queueing)\n  - [Model Temperature](https://docs.roocode.com/features/model-temperature)\n  - [Multi-File Reads](https://docs.roocode.com/features/concurrent-file-reads)\n  - [.rooignore](https://docs.roocode.com/features/rooignore)\n  - [Slash Commands](https://docs.roocode.com/features/slash-commands)\n  - [Suggested Responses](https://docs.roocode.com/features/suggested-responses)\n  - [Task Todo List](https://docs.roocode.com/features/task-todo-list)\n  - [Terminal Shell Integration](https://docs.roocode.com/features/shell-integration)\n  - [MCP](https://docs.roocode.com/advanced-usage/local-models#)\n\n  - [Experimental](https://docs.roocode.com/advanced-usage/local-models#)\n\n  - [Additional Features](https://docs.roocode.com/features/more-features)\n- [Advanced Usage](https://docs.roocode.com/advanced-usage/local-models#)\n\n  - [Available Tools](https://docs.roocode.com/advanced-usage/local-models#)\n\n  - [Context Poisoning](https://docs.roocode.com/advanced-usage/context-poisoning)\n  - [Working with Large Projects](https://docs.roocode.com/advanced-usage/large-projects)\n  - [Using Local Models](https://docs.roocode.com/advanced-usage/local-models)\n  - [Local Development Setup](https://docs.roocode.com/advanced-usage/local-development-setup)\n  - [Prompt Engineering Tips](https://docs.roocode.com/advanced-usage/prompt-engineering)\n  - [Prompt Structure](https://docs.roocode.com/advanced-usage/prompt-structure)\n  - [Rate Limits and Costs](https://docs.roocode.com/advanced-usage/rate-limits-costs)\n  - [Footgun Prompting](https://docs.roocode.com/advanced-usage/footgun-prompting)\n  - [Roo Code Nightly](https://docs.roocode.com/advanced-usage/roo-code-nightly)\n- [Model Providers](https://docs.roocode.com/advanced-usage/local-models#)\n\n- [FAQ](https://docs.roocode.com/advanced-usage/local-models#)\n\n- [Contributing (GitHub)](https://github.com/RooCodeInc/Roo-Code/blob/main/CONTRIBUTING.md)\n- [Roocabulary (GitHub)](https://github.com/cannuri/Roocabulary)\n- [Update Notes](https://docs.roocode.com/advanced-usage/local-models#)\n\n\n- [Home page](https://docs.roocode.com/)\n- Advanced Usage\n- Using Local Models\n\nCopy Page\n\nOn this page\n\n# Using Local Models\n\nRoo Code supports running language models locally on your own machine using [Ollama](https://ollama.com/) and [LM Studio](https://lmstudio.ai/). This offers several advantages:\n\n- **Privacy:** Your code and data never leave your computer.\n- **Offline Access:** You can use Roo Code even without an internet connection.\n- **Cost Savings:** Avoid API usage fees associated with cloud-based models.\n- **Customization:** Experiment with different models and configurations.\n\n**However, using local models also has some drawbacks:**\n\n- **Resource Requirements:** Local models can be resource-intensive, requiring a powerful computer with a good CPU and, ideally, a dedicated GPU.\n- **Setup Complexity:** Setting up local models can be more complex than using cloud-based APIs.\n- **Model Performance:** The performance of local models can vary significantly. While some are excellent, they may not always match the capabilities of the largest, most advanced cloud models.\n- **Limited Features**: Local models (and many online models) often do not support advanced features such as prompt caching, computer use, and others.\n\n* * *\n\n## Supported Local Model Providers [​](https://docs.roocode.com/advanced-usage/local-models\\#supported-local-model-providers \"Direct link to Supported Local Model Providers\")\n\nRoo Code currently supports two main local model providers:\n\n1. **Ollama:** A popular open-source tool for running large language models locally. It supports a wide range of models.\n2. **LM Studio:** A user-friendly desktop application that simplifies the process of downloading, configuring, and running local models. It also provides a local server that emulates the OpenAI API.\n\n* * *\n\n## Setting Up Local Models [​](https://docs.roocode.com/advanced-usage/local-models\\#setting-up-local-models \"Direct link to Setting Up Local Models\")\n\nFor detailed setup instructions, see:\n\n- [Setting up Ollama](https://docs.roocode.com/providers/ollama)\n- [Setting up LM Studio](https://docs.roocode.com/providers/lmstudio)\n\nBoth providers offer similar capabilities but with different user interfaces and workflows. Ollama provides more control through its command-line interface, while LM Studio offers a more user-friendly graphical interface.\n\n* * *\n\n## Troubleshooting [​](https://docs.roocode.com/advanced-usage/local-models\\#troubleshooting \"Direct link to Troubleshooting\")\n\n- **\"No connection could be made because the target machine actively refused it\":** This usually means that the Ollama or LM Studio server isn't running, or is running on a different port/address than Roo Code is configured to use. Double-check the Base URL setting.\n\n- **Slow Response Times:** Local models can be slower than cloud-based models, especially on less powerful hardware. If performance is an issue, try using a smaller model.\n\n- **Model Not Found:** Ensure you have typed in the name of the model correctly. If you're using Ollama, use the same name that you provide in the `ollama run` command.\n\n\n[Edit this page](https://github.com/RooCodeInc/Roo-Code-Docs/edit/main/docs/advanced-usage/local-models.md)\n\nLast updated on **Oct 3, 2025**\n\n[Previous\\\\\n\\\\\nWorking with Large Projects](https://docs.roocode.com/advanced-usage/large-projects) [Next\\\\\n\\\\\nLocal Development Setup](https://docs.roocode.com/advanced-usage/local-development-setup)\n\n- [Supported Local Model Providers](https://docs.roocode.com/advanced-usage/local-models#supported-local-model-providers)\n- [Setting Up Local Models](https://docs.roocode.com/advanced-usage/local-models#setting-up-local-models)\n- [Troubleshooting](https://docs.roocode.com/advanced-usage/local-models#troubleshooting)\n\n![Roo Code Logo](https://docs.roocode.com/img/roo-code-logo-dark.png)\n\nEmpowering developers to build better software faster with AI-powered tools and insights.\n\n[GitHub](https://github.com/RooCodeInc/Roo-Code)[Discord](https://discord.gg/roocode)[Reddit](https://www.reddit.com/r/RooCode/)[X (Twitter)](https://x.com/roo_code)[LinkedIn](https://www.linkedin.com/company/roo-code)[TikTok](https://www.tiktok.com/@roo.code)[Bluesky](https://bsky.app/profile/roocode.bsky.social)\n\nGitHub\n\n- [Issues](https://github.com/RooCodeInc/Roo-Code/issues)\n- [Feature Requests](https://github.com/RooCodeInc/Roo-Code/discussions/categories/feature-requests?discussions_q=is%3Aopen+category%3A%22Feature+Requests%22+sort%3Atop)\n\nDownload\n\n- [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline)\n- [Open VSX Registry](https://open-vsx.org/extension/RooVeterinaryInc/roo-cline)\n\nCompany\n\n- [Contact](mailto:support@roocode.com)\n- [Careers](https://careers.roocode.com/)\n- [Website Privacy Policy](https://roocode.com/privacy)\n- [Extension Privacy Policy](https://github.com/RooCodeInc/Roo-Code/blob/main/PRIVACY.md)\n\nLike most of the internet, we use cookies. Are you OK with that?\n\nDeclineAccept",
  "metadata": {
    "generator": "Docusaurus v3.9.2",
    "og:url": "https://docs.roocode.com/advanced-usage/local-models",
    "ogDescription": "Learn how to run Roo Code with local AI models using Ollama and LM Studio. Complete setup guide for offline AI coding assistance.",
    "ogTitle": "Using Local Models | Roo Code Documentation",
    "og:type": "website",
    "og:locale": "en_US",
    "og:image": "https://docs.roocode.com/img/social-share.jpg",
    "twitter:card": "summary_large_image",
    "twitter:creator": "@roo_code",
    "docusaurus_locale": "en",
    "viewport": "width=device-width, initial-scale=1.0",
    "docusaurus_tag": "docs-default-current",
    "docsearch:docusaurus_tag": "docs-default-current",
    "favicon": "https://docs.roocode.com/img/favicon.ico",
    "docsearch:language": "en",
    "og:title": "Using Local Models | Roo Code Documentation",
    "description": "Learn how to run Roo Code with local AI models using Ollama and LM Studio. Complete setup guide for offline AI coding assistance.",
    "og:description": "Learn how to run Roo Code with local AI models using Ollama and LM Studio. Complete setup guide for offline AI coding assistance.",
    "keywords": "local models,Ollama,LM Studio,offline AI,local LLM,self-hosted AI,privacy-focused AI",
    "twitter:image": "https://docs.roocode.com/img/social-share.jpg",
    "ogImage": "https://docs.roocode.com/img/social-share.jpg",
    "docsearch:version": "current",
    "docusaurus_version": "current",
    "ogUrl": "https://docs.roocode.com/advanced-usage/local-models",
    "twitter:site": "@roo_code",
    "ogLocale": "en_US",
    "language": "en",
    "title": "Using Local Models | Roo Code Documentation",
    "scrapeId": "0b887797-c3b0-4f29-b8ce-a11ff29ce0e7",
    "sourceURL": "https://docs.roocode.com/advanced-usage/local-models",
    "url": "https://docs.roocode.com/advanced-usage/local-models",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic",
    "cacheState": "miss",
    "creditsUsed": 1
  }
}