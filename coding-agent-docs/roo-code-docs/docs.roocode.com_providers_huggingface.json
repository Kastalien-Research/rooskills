{
  "markdown": "Get comprehensive, actionable reviews directly in your PRs. [Try Roo's PR Reviewer](https://roocode.com/reviewer?utm_source=docs&utm_medium=banner&utm_campaign=reviewer_promo)\n\n[Skip to main content](https://docs.roocode.com/providers/huggingface#__docusaurus_skipToContent_fallback)\n\n[![Roo Code Logo](https://docs.roocode.com/img/roo-code-logo-dark.png)](https://docs.roocode.com/)\n\n`ctrl`  `K`\n\n[Reddit](https://www.reddit.com/r/RooCode/ \"Reddit\")[Discord](https://discord.gg/roocode \"Discord\")\n\n[20.3k](https://github.com/RooCodeInc/Roo-Code \"GitHub Repository\") [Install ·935.9k](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline \"Install VS Code Extension\")\n\n- [Welcome](https://docs.roocode.com/)\n- [Getting Started](https://docs.roocode.com/providers/huggingface#)\n\n- [Tutorial Videos](https://docs.roocode.com/providers/huggingface#)\n\n- [Roo Code Cloud](https://docs.roocode.com/providers/huggingface#)\n\n- Features\n\n  - [API Configuration Profiles](https://docs.roocode.com/features/api-configuration-profiles)\n  - [Auto-Approving Actions](https://docs.roocode.com/features/auto-approving-actions)\n  - [Boomerang Tasks](https://docs.roocode.com/features/boomerang-tasks)\n  - [Browser Use](https://docs.roocode.com/features/browser-use)\n  - [Checkpoints](https://docs.roocode.com/features/checkpoints)\n  - [Code Actions](https://docs.roocode.com/features/code-actions)\n  - [Codebase Indexing](https://docs.roocode.com/features/codebase-indexing)\n  - [Custom Instructions](https://docs.roocode.com/features/custom-instructions)\n  - [Diagnostics Integration](https://docs.roocode.com/features/diagnostics-integration)\n  - [Customizing Modes](https://docs.roocode.com/features/custom-modes)\n  - [Diff/Fast Edits](https://docs.roocode.com/features/fast-edits)\n  - [Enhance Prompt](https://docs.roocode.com/features/enhance-prompt)\n  - [Import/Export/Reset Settings](https://docs.roocode.com/features/settings-management)\n  - [Intelligent Context Condensing](https://docs.roocode.com/features/intelligent-context-condensing)\n  - [Keyboard Navigation](https://docs.roocode.com/features/keyboard-shortcuts)\n  - [Roo Code Marketplace](https://docs.roocode.com/features/marketplace)\n  - [Message Queueing](https://docs.roocode.com/features/message-queueing)\n  - [Model Temperature](https://docs.roocode.com/features/model-temperature)\n  - [Multi-File Reads](https://docs.roocode.com/features/concurrent-file-reads)\n  - [.rooignore](https://docs.roocode.com/features/rooignore)\n  - [Slash Commands](https://docs.roocode.com/features/slash-commands)\n  - [Suggested Responses](https://docs.roocode.com/features/suggested-responses)\n  - [Task Todo List](https://docs.roocode.com/features/task-todo-list)\n  - [Terminal Shell Integration](https://docs.roocode.com/features/shell-integration)\n  - [MCP](https://docs.roocode.com/providers/huggingface#)\n\n  - [Experimental](https://docs.roocode.com/providers/huggingface#)\n\n  - [Additional Features](https://docs.roocode.com/features/more-features)\n- [Advanced Usage](https://docs.roocode.com/providers/huggingface#)\n\n- [Model Providers](https://docs.roocode.com/providers/huggingface#)\n\n  - [Anthropic](https://docs.roocode.com/providers/anthropic)\n  - [Claude Code](https://docs.roocode.com/providers/claude-code)\n  - [AWS Bedrock](https://docs.roocode.com/providers/bedrock)\n  - [Cerebras](https://docs.roocode.com/providers/cerebras)\n  - [DeepInfra](https://docs.roocode.com/providers/deepinfra)\n  - [DeepSeek](https://docs.roocode.com/providers/deepseek)\n  - [Doubao](https://docs.roocode.com/providers/doubao)\n  - [Featherless AI](https://docs.roocode.com/providers/featherless)\n  - [Fireworks AI](https://docs.roocode.com/providers/fireworks)\n  - [Chutes AI](https://docs.roocode.com/providers/chutes)\n  - [Google Gemini](https://docs.roocode.com/providers/gemini)\n  - [Glama](https://docs.roocode.com/providers/glama)\n  - [Groq](https://docs.roocode.com/providers/groq)\n  - [Hugging Face](https://docs.roocode.com/providers/huggingface)\n  - [Human Relay](https://docs.roocode.com/providers/human-relay)\n  - [IO Intelligence Provider](https://docs.roocode.com/providers/io-intelligence)\n  - [LM Studio](https://docs.roocode.com/providers/lmstudio)\n  - [LiteLLM](https://docs.roocode.com/providers/litellm)\n  - [Mistral AI](https://docs.roocode.com/providers/mistral)\n  - [Ollama](https://docs.roocode.com/providers/ollama)\n  - [OpenAI](https://docs.roocode.com/providers/openai)\n  - [OpenAI Compatible](https://docs.roocode.com/providers/openai-compatible)\n  - [OpenRouter](https://docs.roocode.com/providers/openrouter)\n  - [Qwen Code CLI](https://docs.roocode.com/providers/qwen-code)\n  - [Requesty](https://docs.roocode.com/providers/requesty)\n  - [Roo Code Cloud](https://docs.roocode.com/providers/roo-code-cloud)\n  - [SambaNova](https://docs.roocode.com/providers/sambanova)\n  - [Unbound](https://docs.roocode.com/providers/unbound)\n  - [Vercel AI Gateway](https://docs.roocode.com/providers/vercel-ai-gateway)\n  - [GCP Vertex AI](https://docs.roocode.com/providers/vertex)\n  - [VS Code Language Model API](https://docs.roocode.com/providers/vscode-lm)\n  - [xAI (Grok)](https://docs.roocode.com/providers/xai)\n  - [Z AI](https://docs.roocode.com/providers/zai)\n- [FAQ](https://docs.roocode.com/providers/huggingface#)\n\n- [Contributing (GitHub)](https://github.com/RooCodeInc/Roo-Code/blob/main/CONTRIBUTING.md)\n- [Roocabulary (GitHub)](https://github.com/cannuri/Roocabulary)\n- [Update Notes](https://docs.roocode.com/providers/huggingface#)\n\n\n- [Home page](https://docs.roocode.com/)\n- Model Providers\n- Hugging Face\n\nCopy Page\n\nOn this page\n\n# Using Hugging Face With Roo Code\n\nRoo Code integrates with the Hugging Face router to provide access to a curated collection of open-source models optimized for code assistance. The integration allows you to choose from multiple inference providers and automatically selects the best available option.\n\n**Website:** [https://huggingface.co/](https://huggingface.co/)\n\n* * *\n\n## Getting an API Key [​](https://docs.roocode.com/providers/huggingface\\#getting-an-api-key \"Direct link to Getting an API Key\")\n\n1. **Sign Up/Sign In:** Go to [Hugging Face](https://huggingface.co/) and create an account or sign in.\n2. **Navigate to Settings:** Click on your profile picture and select \"Settings\".\n3. **Access Tokens:** Go to the \"Access Tokens\" section in your settings.\n4. **Create Token:** Click \"New token\" and give it a descriptive name (e.g., \"Roo Code\").\n5. **Set Permissions:** Select \"Read\" permissions (this is sufficient for Roo Code).\n6. **Copy Token:** **Important:** Copy the token immediately. Store it securely.\n\n* * *\n\n## Supported Models [​](https://docs.roocode.com/providers/huggingface\\#supported-models \"Direct link to Supported Models\")\n\nRoo Code displays models from the 'roocode' collection on Hugging Face, which includes curated open-source models optimized for code assistance. The default model is `meta-llama/Llama-3.3-70B-Instruct` if no model is selected.\n\nAvailable models are dynamically retrieved from the Hugging Face API. The exact list of models may vary based on availability. Both the model and provider dropdowns are searchable, allowing you to quickly find specific options.\n\n* * *\n\n## Configuration in Roo Code [​](https://docs.roocode.com/providers/huggingface\\#configuration-in-roo-code \"Direct link to Configuration in Roo Code\")\n\n1. **Open Roo Code Settings:** Click the gear icon () in the Roo Code panel.\n2. **Select Provider:** Choose \"Hugging Face\" from the \"API Provider\" dropdown.\n3. **Enter API Key:** Paste your Hugging Face API token into the \"Hugging Face API Key\" field.\n4. **Select Model:** Choose your desired model from the \"Model\" dropdown. The dropdown shows the model count and is searchable.\n5. **Choose Inference Provider (Optional):** Select a specific inference provider from the dropdown, or leave it on \"Auto\" (default) to automatically select the best available provider.\n\n* * *\n\n## Inference Provider Selection [​](https://docs.roocode.com/providers/huggingface\\#inference-provider-selection \"Direct link to Inference Provider Selection\")\n\nHugging Face's router connects to multiple inference providers. You can either:\n\n- **Auto Mode (Default):** Automatically selects the best available provider based on model availability and performance\n- **Manual Selection:** Choose a specific provider from the dropdown\n\nThe dropdown displays the status of each provider:\n\n- `live` \\- Provider is operational and available\n- `staging` \\- Provider is in testing phase\n- `error` \\- Provider is currently experiencing issues\n\nProvider names are formatted for better readability in the UI (e.g., \"sambanova\" appears as \"SambaNova\").\n\nWhen you select a specific provider, the model capabilities (max tokens, pricing) will update to reflect that provider's specific configuration. Pricing information is only displayed when a specific provider is selected, not in Auto mode.\n\n* * *\n\n## Model Information Display [​](https://docs.roocode.com/providers/huggingface\\#model-information-display \"Direct link to Model Information Display\")\n\nFor each selected model, Roo Code displays:\n\n- **Max Output:** The maximum number of tokens the model can generate (varies by provider)\n- **Pricing:** Cost per million input and output tokens (displayed only when a specific provider is selected)\n- **Image Support:** Currently, all models are shown as text-only. This is a Roo Code implementation limitation, not a restriction of the Hugging Face API.\n\n* * *\n\n## Available Providers [​](https://docs.roocode.com/providers/huggingface\\#available-providers \"Direct link to Available Providers\")\n\nThe list of available providers is dynamic and retrieved from the Hugging Face API. Common providers include:\n\n- **Together AI** \\- High-performance inference platform\n- **Fireworks AI** \\- Fast and scalable model serving\n- **DeepInfra** \\- Cost-effective GPU infrastructure\n- **Hyperbolic** \\- Optimized inference service\n- **Cerebras** \\- Hardware-accelerated inference\n\n_Note: The providers shown above are examples of commonly available options. The actual list may vary._\n\n* * *\n\n## Tips and Notes [​](https://docs.roocode.com/providers/huggingface\\#tips-and-notes \"Direct link to Tips and Notes\")\n\n- **Provider Failover:** When using Auto mode, if the selected provider fails, Hugging Face's infrastructure will automatically try alternative providers\n- **Rate Limits:** Different providers may have different rate limits and availability\n- **Pricing Variability:** Costs can vary significantly between providers for the same model\n- **Model Updates:** The roocode collection is regularly updated with new and improved models\n\n[Edit this page](https://github.com/RooCodeInc/Roo-Code-Docs/edit/main/docs/providers/huggingface.md)\n\nLast updated on **Oct 3, 2025**\n\n[Previous\\\\\n\\\\\nGroq](https://docs.roocode.com/providers/groq) [Next\\\\\n\\\\\nHuman Relay](https://docs.roocode.com/providers/human-relay)\n\n- [Getting an API Key](https://docs.roocode.com/providers/huggingface#getting-an-api-key)\n- [Supported Models](https://docs.roocode.com/providers/huggingface#supported-models)\n- [Configuration in Roo Code](https://docs.roocode.com/providers/huggingface#configuration-in-roo-code)\n- [Inference Provider Selection](https://docs.roocode.com/providers/huggingface#inference-provider-selection)\n- [Model Information Display](https://docs.roocode.com/providers/huggingface#model-information-display)\n- [Available Providers](https://docs.roocode.com/providers/huggingface#available-providers)\n- [Tips and Notes](https://docs.roocode.com/providers/huggingface#tips-and-notes)\n\n![Roo Code Logo](https://docs.roocode.com/img/roo-code-logo-dark.png)\n\nEmpowering developers to build better software faster with AI-powered tools and insights.\n\n[GitHub](https://github.com/RooCodeInc/Roo-Code)[Discord](https://discord.gg/roocode)[Reddit](https://www.reddit.com/r/RooCode/)[X (Twitter)](https://x.com/roo_code)[LinkedIn](https://www.linkedin.com/company/roo-code)[TikTok](https://www.tiktok.com/@roo.code)[Bluesky](https://bsky.app/profile/roocode.bsky.social)\n\nGitHub\n\n- [Issues](https://github.com/RooCodeInc/Roo-Code/issues)\n- [Feature Requests](https://github.com/RooCodeInc/Roo-Code/discussions/categories/feature-requests?discussions_q=is%3Aopen+category%3A%22Feature+Requests%22+sort%3Atop)\n\nDownload\n\n- [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline)\n- [Open VSX Registry](https://open-vsx.org/extension/RooVeterinaryInc/roo-cline)\n\nCompany\n\n- [Contact](mailto:support@roocode.com)\n- [Careers](https://careers.roocode.com/)\n- [Website Privacy Policy](https://roocode.com/privacy)\n- [Extension Privacy Policy](https://github.com/RooCodeInc/Roo-Code/blob/main/PRIVACY.md)\n\nLike most of the internet, we use cookies. Are you OK with that?\n\nDeclineAccept",
  "metadata": {
    "og:locale": "en_US",
    "docsearch:language": "en",
    "og:image": "https://docs.roocode.com/img/social-share.jpg",
    "docusaurus_version": "current",
    "docsearch:docusaurus_tag": "docs-default-current",
    "keywords": "hugging face,huggingface,roo code,api provider,open source models,llama,mistral,inference router,ai models,inference providers",
    "title": "Using Hugging Face With Roo Code | Roo Code Documentation",
    "twitter:card": "summary_large_image",
    "twitter:site": "@roo_code",
    "favicon": "https://docs.roocode.com/img/favicon.ico",
    "language": "en",
    "og:type": "website",
    "og:url": "https://docs.roocode.com/providers/huggingface",
    "twitter:image": "https://docs.roocode.com/img/social-share.jpg",
    "docsearch:version": "current",
    "docusaurus_tag": "docs-default-current",
    "ogLocale": "en_US",
    "og:title": "Using Hugging Face With Roo Code | Roo Code Documentation",
    "description": "Connect Roo Code to Hugging Face's inference router for access to open-source LLMs. Choose from multiple inference providers and models like Llama, Mistral, and more.",
    "viewport": "width=device-width, initial-scale=1.0",
    "og:description": "Connect Roo Code to Hugging Face's inference router for access to open-source LLMs. Choose from multiple inference providers and models like Llama, Mistral, and more.",
    "ogImage": "https://docs.roocode.com/img/social-share.jpg",
    "generator": "Docusaurus v3.9.2",
    "twitter:creator": "@roo_code",
    "ogDescription": "Connect Roo Code to Hugging Face's inference router for access to open-source LLMs. Choose from multiple inference providers and models like Llama, Mistral, and more.",
    "ogTitle": "Using Hugging Face With Roo Code | Roo Code Documentation",
    "ogUrl": "https://docs.roocode.com/providers/huggingface",
    "docusaurus_locale": "en",
    "scrapeId": "57528249-f98a-4e1b-995a-66af6fc1b531",
    "sourceURL": "https://docs.roocode.com/providers/huggingface",
    "url": "https://docs.roocode.com/providers/huggingface",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic",
    "cacheState": "miss",
    "indexId": "5088ac00-8ece-4412-b588-dcae6c9be06c",
    "creditsUsed": 1
  }
}